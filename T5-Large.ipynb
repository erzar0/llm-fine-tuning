{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:42:11.700537800Z",
     "start_time": "2025-05-03T16:42:11.618205200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "NOTEBOOK_DIR = Path(\"/\".join(__vsc_ipynb_file__.split(\"/\")[:-1]))\n",
    "print(NOTEBOOK_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:42:27.943605900Z",
     "start_time": "2025-05-03T16:42:11.644206700Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available data subsets: dict_keys(['train', 'test'])\n",
      "Features: \n",
      "---> id                            : 5097\n",
      "---> domain                        : forestry\n",
      "---> domain_description            : Comprehensive data on sustainable forest management, timber production, wildlife habitat, and carbon sequestration in forestry.\n",
      "---> sql_complexity                : single join\n",
      "---> sql_complexity_description    : only one join (specify inner, outer, cross)\n",
      "---> sql_task_type                 : analytics and reporting\n",
      "---> sql_task_type_description     : generating reports, dashboards, and analytical insights\n",
      "---> sql_prompt                    : What is the total volume of timber sold by each salesperson, sorted by salesperson?\n",
      "---> sql_context                   : CREATE TABLE salesperson (salesperson_id INT, name TEXT, region TEXT); INSERT INTO salesperson (salesperson_id, name, region) VALUES (1, 'John Doe', 'North'), (2, 'Jane Smith', 'South'); CREATE TABLE timber_sales (sales_id INT, salesperson_id INT, volume REAL, sale_date DATE); INSERT INTO timber_sales (sales_id, salesperson_id, volume, sale_date) VALUES (1, 1, 120, '2021-01-01'), (2, 1, 150, '2021-02-01'), (3, 2, 180, '2021-01-01');\n",
      "---> sql                           : SELECT salesperson_id, name, SUM(volume) as total_volume FROM timber_sales JOIN salesperson ON timber_sales.salesperson_id = salesperson.salesperson_id GROUP BY salesperson_id, name ORDER BY total_volume DESC;\n",
      "---> sql_explanation               : Joins timber_sales and salesperson tables, groups sales by salesperson, calculates total volume sold by each salesperson, and orders the results by total volume in descending order.\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/datasets/gretelai/synthetic_text_to_sql\n",
    "dataset = load_dataset(\"gretelai/synthetic_text_to_sql\")\n",
    "\n",
    "print(\"Available data subsets:\", dataset.keys())\n",
    "print(\"Features: \")\n",
    "for k, v in dataset[\"train\"][0].items():\n",
    "    print(f\"---> {k:30}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(dataset[\"train\"])\n",
    "test_df = pd.DataFrame(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:43:15.028542700Z",
     "start_time": "2025-05-03T16:42:27.948187200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset columns: ['id', 'domain', 'domain_description', 'sql_complexity', 'sql_complexity_description', 'sql_task_type', 'sql_task_type_description', 'sql_prompt', 'sql_context', 'sql', 'sql_explanation']\n",
      "Checking 'train' split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:09<00:09,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sql_prompt: 0 missing or empty entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:19<00:00,  9.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sql: 0 missing or empty entries\n",
      "\n",
      "Checking 'test' split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sql_prompt: 0 missing or empty entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sql: 0 missing or empty entries\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def check_missing_data(dataset, columns):\n",
    "    for split in dataset.keys():\n",
    "        print(f\"Checking '{split}' split...\")\n",
    "        for column in tqdm(columns):\n",
    "            if column not in dataset[split].column_names:\n",
    "                print(f\"  Column '{column}' not found in the dataset!\")\n",
    "                continue\n",
    "            missing_count = sum(1 for example in dataset[split] if not example[column] or example[column].strip() == \"\")\n",
    "            print(f\"  {column}: {missing_count} missing or empty entries\")\n",
    "        print()\n",
    "\n",
    "print(\"Dataset columns:\", dataset[\"train\"].column_names)\n",
    "check_missing_data(dataset, columns=[\"sql_prompt\", \"sql\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:43:15.394083700Z",
     "start_time": "2025-05-03T16:43:15.004673300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    text = text.lower().strip().replace(\"\\n\", \" \")\n",
    "    return text\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:45:39.565195200Z",
     "start_time": "2025-05-03T16:43:15.399414900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    input_text = \"Translate to SQL: \" + normalize_text(example[\"sql_prompt\"])\n",
    "    output_text = normalize_text(example[\"sql\"])\n",
    "\n",
    "    model_inputs = tokenizer(input_text, truncation=True, padding=\"max_length\", max_length=128)\n",
    "    labels = tokenizer(output_text, truncation=True, padding=\"max_length\", max_length=128)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_ds = dataset.map(preprocess, remove_columns=dataset[\"train\"].column_names)\n",
    "\n",
    "available_splits = dataset.keys()\n",
    "train_ds = tokenized_ds[\"train\"]\n",
    "validation_ds = tokenized_ds[\"test\"] if \"test\" in available_splits else None\n",
    "test_ds = tokenized_ds[\"test\"] if \"test\" in available_splits else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining llamafactory from git+https://github.com/hiyouga/LLaMA-Factory.git@52f25651a2016ddede2283be17cf40c2c1b906ed#egg=llamafactory (from -r requirements/requirements.txt (line 84))\n",
      "  Skipping because already up-to-date.\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting accelerate==1.6.0 (from -r requirements/requirements.txt (line 1))\n",
      "  Using cached accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting aiofiles==24.1.0 (from -r requirements/requirements.txt (line 2))\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs==2.6.1 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 3)) (2.6.1)\n",
      "Collecting aiohttp==3.11.18 (from -r requirements/requirements.txt (line 4))\n",
      "  Using cached aiohttp-3.11.18-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: aiosignal==1.3.2 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 5)) (1.3.2)\n",
      "Collecting airportsdata==20250224 (from -r requirements/requirements.txt (line 6))\n",
      "  Using cached airportsdata-20250224-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting annotated-types==0.7.0 (from -r requirements/requirements.txt (line 7))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.3 (from -r requirements/requirements.txt (line 8))\n",
      "  Using cached antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: anyio==4.9.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 9)) (4.9.0)\n",
      "Collecting astor==0.8.1 (from -r requirements/requirements.txt (line 10))\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: asttokens==3.0.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 11)) (3.0.0)\n",
      "Requirement already satisfied: attrs==25.3.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 12)) (25.3.0)\n",
      "Collecting audioread==3.0.1 (from -r requirements/requirements.txt (line 13))\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting av==14.3.0 (from -r requirements/requirements.txt (line 14))\n",
      "  Using cached av-14.3.0-cp312-cp312-win_amd64.whl.metadata (4.8 kB)\n",
      "Collecting bitsandbytes==0.45.5 (from -r requirements/requirements.txt (line 15))\n",
      "  Using cached bitsandbytes-0.45.5-py3-none-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting blake3==1.0.5 (from -r requirements/requirements.txt (line 16))\n",
      "  Using cached blake3-1.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting cachetools==5.5.2 (from -r requirements/requirements.txt (line 17))\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: certifi==2025.4.26 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 18)) (2025.4.26)\n",
      "Requirement already satisfied: cffi==1.17.1 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 19)) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer==3.4.2 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 20)) (3.4.2)\n",
      "Collecting click==8.1.8 (from -r requirements/requirements.txt (line 21))\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting cloudpickle==3.1.1 (from -r requirements/requirements.txt (line 22))\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: comm==0.2.2 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 23)) (0.2.2)\n",
      "Collecting compressed-tensors==0.9.3 (from -r requirements/requirements.txt (line 24))\n",
      "  Using cached compressed_tensors-0.9.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting contourpy==1.3.2 (from -r requirements/requirements.txt (line 25))\n",
      "  Using cached contourpy-1.3.2-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cupy-cuda12x==13.4.1 (from -r requirements/requirements.txt (line 26))\n",
      "  Using cached cupy_cuda12x-13.4.1-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Collecting cycler==0.12.1 (from -r requirements/requirements.txt (line 27))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting datasets==3.5.0 (from -r requirements/requirements.txt (line 28))\n",
      "  Using cached datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: debugpy==1.8.14 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 29)) (1.8.14)\n",
      "Requirement already satisfied: decorator==5.2.1 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 30)) (5.2.1)\n",
      "Collecting Deprecated==1.2.18 (from -r requirements/requirements.txt (line 31))\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting depyf==0.18.0 (from -r requirements/requirements.txt (line 32))\n",
      "  Using cached depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: dill==0.3.8 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 33)) (0.3.8)\n",
      "Collecting diskcache==5.6.3 (from -r requirements/requirements.txt (line 34))\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting distro==1.9.0 (from -r requirements/requirements.txt (line 35))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting dnspython==2.7.0 (from -r requirements/requirements.txt (line 36))\n",
      "  Using cached dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting docker-pycreds==0.4.0 (from -r requirements/requirements.txt (line 37))\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting docstring_parser==0.16 (from -r requirements/requirements.txt (line 38))\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting einops==0.8.1 (from -r requirements/requirements.txt (line 39))\n",
      "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting email_validator==2.2.0 (from -r requirements/requirements.txt (line 40))\n",
      "  Using cached email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: evaluate==0.4.3 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 41)) (0.4.3)\n",
      "Requirement already satisfied: executing==2.2.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 42)) (2.2.0)\n",
      "Collecting fastapi==0.115.12 (from -r requirements/requirements.txt (line 43))\n",
      "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting fastapi-cli==0.0.7 (from -r requirements/requirements.txt (line 44))\n",
      "  Using cached fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting fastrlock==0.8.3 (from -r requirements/requirements.txt (line 45))\n",
      "  Using cached fastrlock-0.8.3-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting ffmpy==0.5.0 (from -r requirements/requirements.txt (line 46))\n",
      "  Using cached ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: filelock==3.18.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 47)) (3.18.0)\n",
      "Collecting fire==0.7.0 (from -r requirements/requirements.txt (line 48))\n",
      "  Using cached fire-0.7.0.tar.gz (87 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting fonttools==4.57.0 (from -r requirements/requirements.txt (line 49))\n",
      "  Using cached fonttools-4.57.0-cp312-cp312-win_amd64.whl.metadata (104 kB)\n",
      "Requirement already satisfied: frozenlist==1.6.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 50)) (1.6.0)\n",
      "Collecting fsspec==2024.12.0 (from -r requirements/requirements.txt (line 51))\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gguf==0.16.3 (from -r requirements/requirements.txt (line 52))\n",
      "  Using cached gguf-0.16.3-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting gitdb==4.0.12 (from -r requirements/requirements.txt (line 53))\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting GitPython==3.1.44 (from -r requirements/requirements.txt (line 54))\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting googleapis-common-protos==1.70.0 (from -r requirements/requirements.txt (line 55))\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting gradio==5.25.0 (from -r requirements/requirements.txt (line 56))\n",
      "  Using cached gradio-5.25.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting gradio_client==1.8.0 (from -r requirements/requirements.txt (line 57))\n",
      "  Using cached gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy==0.1.2 (from -r requirements/requirements.txt (line 58))\n",
      "  Using cached groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting grpcio==1.71.0 (from -r requirements/requirements.txt (line 59))\n",
      "  Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: h11==0.16.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 60)) (0.16.0)\n",
      "Collecting hf-xet==1.1.0 (from -r requirements/requirements.txt (line 61))\n",
      "  Using cached hf_xet-1.1.0-cp37-abi3-win_amd64.whl.metadata (498 bytes)\n",
      "Requirement already satisfied: httpcore==1.0.9 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 62)) (1.0.9)\n",
      "Collecting httptools==0.6.4 (from -r requirements/requirements.txt (line 63))\n",
      "  Using cached httptools-0.6.4-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: httpx==0.28.1 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 64)) (0.28.1)\n",
      "Collecting huggingface-hub==0.30.2 (from -r requirements/requirements.txt (line 65))\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: idna==3.10 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 66)) (3.10)\n",
      "Collecting importlib_metadata==8.0.0 (from -r requirements/requirements.txt (line 67))\n",
      "  Using cached importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting interegular==0.3.3 (from -r requirements/requirements.txt (line 68))\n",
      "  Using cached interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 69)) (6.29.5)\n",
      "Collecting ipython==9.2.0 (from -r requirements/requirements.txt (line 70))\n",
      "  Using cached ipython-9.2.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 71)) (1.1.1)\n",
      "Requirement already satisfied: jedi==0.19.2 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 72)) (0.19.2)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 73)) (3.1.6)\n",
      "Collecting jiter==0.10.0 (from -r requirements/requirements.txt (line 74))\n",
      "  Using cached jiter-0.10.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting joblib==1.4.2 (from -r requirements/requirements.txt (line 75))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting jsonschema==4.23.0 (from -r requirements/requirements.txt (line 76))\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: jsonschema-specifications==2025.4.1 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 77)) (2025.4.1)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 78)) (8.6.3)\n",
      "Collecting jupyter_core==5.7.2 (from -r requirements/requirements.txt (line 79))\n",
      "  Using cached jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting kiwisolver==1.4.8 (from -r requirements/requirements.txt (line 80))\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting lark==1.2.2 (from -r requirements/requirements.txt (line 81))\n",
      "  Using cached lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting lazy_loader==0.4 (from -r requirements/requirements.txt (line 82))\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting librosa==0.11.0 (from -r requirements/requirements.txt (line 83))\n",
      "  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting llguidance==0.7.20 (from -r requirements/requirements.txt (line 85))\n",
      "  Using cached llguidance-0.7.20-cp39-abi3-win_amd64.whl.metadata (9.7 kB)\n",
      "Collecting llvmlite==0.44.0 (from -r requirements/requirements.txt (line 86))\n",
      "  Using cached llvmlite-0.44.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting lm-format-enforcer==0.10.11 (from -r requirements/requirements.txt (line 87))\n",
      "  Using cached lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting markdown-it-py==3.0.0 (from -r requirements/requirements.txt (line 88))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 89)) (3.0.2)\n",
      "Collecting matplotlib==3.10.1 (from -r requirements/requirements.txt (line 90))\n",
      "  Using cached matplotlib-3.10.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 91)) (0.1.7)\n",
      "Collecting mdurl==0.1.2 (from -r requirements/requirements.txt (line 92))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting mistral_common==1.5.4 (from -r requirements/requirements.txt (line 93))\n",
      "  Using cached mistral_common-1.5.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: mpmath==1.3.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 94)) (1.3.0)\n",
      "Collecting msgpack==1.1.0 (from -r requirements/requirements.txt (line 95))\n",
      "  Using cached msgpack-1.1.0-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting msgspec==0.19.0 (from -r requirements/requirements.txt (line 96))\n",
      "  Using cached msgspec-0.19.0-cp312-cp312-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting multidict==6.4.3 (from -r requirements/requirements.txt (line 97))\n",
      "  Using cached multidict-6.4.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: multiprocess==0.70.16 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 98)) (0.70.16)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from -r requirements/requirements.txt (line 99)) (1.6.0)\n",
      "Collecting networkx==3.4.2 (from -r requirements/requirements.txt (line 100))\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting ninja==1.11.1.4 (from -r requirements/requirements.txt (line 101))\n",
      "  Using cached ninja-1.11.1.4-py3-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting numba==0.61.2 (from -r requirements/requirements.txt (line 102))\n",
      "  Using cached numba-0.61.2-cp312-cp312-win_amd64.whl.metadata (2.9 kB)\n",
      "Collecting numpy==1.26.4 (from -r requirements/requirements.txt (line 103))\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from -r requirements/requirements.txt (line 104))\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from -r requirements/requirements.txt (line 105))\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from -r requirements/requirements.txt (line 106))\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from -r requirements/requirements.txt (line 107))\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from -r requirements/requirements.txt (line 108))\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from -r requirements/requirements.txt (line 109))\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-win_amd64.whl.metadata (1.5 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 0.36.0 Requires-Python >=3.6,<3.10; 0.37.0 Requires-Python >=3.7,<3.10; 0.38.0 Requires-Python >=3.7,<3.11; 0.38.1 Requires-Python >=3.7,<3.11; 0.52.0 Requires-Python >=3.6,<3.9; 0.52.0rc3 Requires-Python >=3.6,<3.9; 0.53.0 Requires-Python >=3.6,<3.10; 0.53.0rc1.post1 Requires-Python >=3.6,<3.10; 0.53.0rc2 Requires-Python >=3.6,<3.10; 0.53.0rc3 Requires-Python >=3.6,<3.10; 0.53.1 Requires-Python >=3.6,<3.10; 0.54.0 Requires-Python >=3.7,<3.10; 0.54.0rc2 Requires-Python >=3.7,<3.10; 0.54.0rc3 Requires-Python >=3.7,<3.10; 0.54.1 Requires-Python >=3.7,<3.10; 0.55.0 Requires-Python >=3.7,<3.11; 0.55.0rc1 Requires-Python >=3.7,<3.11; 0.55.1 Requires-Python >=3.7,<3.11; 0.55.2 Requires-Python >=3.7,<3.11; 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\n",
      "ERROR: Could not find a version that satisfies the requirement nvidia-cufile-cu12==1.11.1.6 (from versions: none)\n",
      "ERROR: No matching distribution found for nvidia-cufile-cu12==1.11.1.6\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from accelerate>=0.26.0) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from accelerate>=0.26.0) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from accelerate>=0.26.0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from accelerate>=0.26.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from accelerate>=0.26.0) (2.7.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from accelerate>=0.26.0) (0.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from accelerate>=0.26.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate>=0.26.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\szymo\\desktop\\programingstuff\\visualstudiocodeprojects\\llm-fine-tuning\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.4.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install \"accelerate>=0.26.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:47:35.804666900Z",
     "start_time": "2025-05-03T16:45:39.573204300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\szymo\\AppData\\Local\\Temp\\ipykernel_13912\\3052652965.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "c:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='62500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    4/62500 06:05 < 3173:53:33, 0.01 it/s, Epoch 0.00/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m      3\u001b[39m training_args = Seq2SeqTrainingArguments(\n\u001b[32m      4\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./sql_model\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     eval_strategy=\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# Changed from evaluation_strategy\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     logging_dir=\u001b[33m\"\u001b[39m\u001b[33m./logs\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m trainer = Seq2SeqTrainer(\n\u001b[32m     17\u001b[39m     model=model,\n\u001b[32m     18\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     tokenizer=tokenizer\n\u001b[32m     22\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\transformers\\trainer.py:2240\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2238\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\transformers\\trainer.py:2555\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2548\u001b[39m context = (\n\u001b[32m   2549\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2550\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2551\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2552\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2553\u001b[39m )\n\u001b[32m   2554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2555\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2558\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2559\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2560\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2561\u001b[39m ):\n\u001b[32m   2562\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2563\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\transformers\\trainer.py:3745\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3744\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3745\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3747\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3749\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3750\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3751\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\transformers\\trainer.py:3810\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3808\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3809\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3810\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3811\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3812\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1811\u001b[39m, in \u001b[36mT5ForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1808\u001b[39m         decoder_attention_mask = decoder_attention_mask.to(\u001b[38;5;28mself\u001b[39m.decoder.first_device)\n\u001b[32m   1810\u001b[39m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1811\u001b[39m decoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1812\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1813\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1814\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1815\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1816\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1817\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1818\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1819\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1820\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1821\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1822\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1823\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1825\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1827\u001b[39m sequence_output = decoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1829\u001b[39m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1124\u001b[39m, in \u001b[36mT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1107\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m   1108\u001b[39m         layer_module.forward,\n\u001b[32m   1109\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1121\u001b[39m         cache_position,\n\u001b[32m   1122\u001b[39m     )\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[32m   1141\u001b[39m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[32m   1142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:679\u001b[39m, in \u001b[36mT5Block.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001b[39m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    664\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    665\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    677\u001b[39m     cache_position=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    678\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    689\u001b[39m     hidden_states, past_key_value = self_attention_outputs[:\u001b[32m2\u001b[39m]\n\u001b[32m    690\u001b[39m     attention_outputs = self_attention_outputs[\u001b[32m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:597\u001b[39m, in \u001b[36mT5LayerSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions, cache_position)\u001b[39m\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    586\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    587\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    594\u001b[39m     cache_position=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    595\u001b[39m ):\n\u001b[32m    596\u001b[39m     normed_hidden_states = \u001b[38;5;28mself\u001b[39m.layer_norm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m597\u001b[39m     attention_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m     hidden_states = hidden_states + \u001b[38;5;28mself\u001b[39m.dropout(attention_output[\u001b[32m0\u001b[39m])\n\u001b[32m    608\u001b[39m     outputs = (hidden_states,) + attention_output[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\szymo\\Desktop\\ProgramingStuff\\VisualStudioCodeProjects\\llm-fine-tuning\\venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:510\u001b[39m, in \u001b[36mT5Attention.forward\u001b[39m\u001b[34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001b[39m\n\u001b[32m    508\u001b[39m key_states = \u001b[38;5;28mself\u001b[39m.k(current_states)\n\u001b[32m    509\u001b[39m value_states = \u001b[38;5;28mself\u001b[39m.v(current_states)\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m key_states = \u001b[43mkey_states\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_value_proj_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    511\u001b[39m value_states = value_states.view(batch_size, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.n_heads, \u001b[38;5;28mself\u001b[39m.key_value_proj_dim).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    514\u001b[39m     \u001b[38;5;66;03m# save all key/value_states to cache to be re-used for fast auto-regressive generation\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-large\")\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./sql_model\",\n",
    "    eval_strategy=\"epoch\",  # Changed from evaluation_strategy\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=validation_ds,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-03T16:47:35.789336800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_model(test_dataset):\n",
    "    metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        decoded_labels = [[label] for label in decoded_labels]\n",
    "        result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "        return {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    results = trainer.evaluate(eval_dataset=test_dataset, compute_metrics=compute_metrics)\n",
    "    return results\n",
    "\n",
    "if test_ds:\n",
    "    test_results = evaluate_model(test_ds)\n",
    "    print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-03T16:47:35.790340500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def driver(question):\n",
    "    inputs = tokenizer(\"Translate to SQL: \" + question, return_tensors=\"pt\").input_ids\n",
    "    outputs = model.generate(inputs, max_length=128)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(driver(\"Find all customers who ordered in 2023\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
