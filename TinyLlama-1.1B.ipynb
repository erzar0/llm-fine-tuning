{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10aacbef",
   "metadata": {},
   "source": [
    "# Mistral-7B\n",
    "- To DO???\n",
    "- Performance\n",
    "- 7 Billion parameters, 24GB at least GPU (VRAM)\n",
    "- Should be best of all selected models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c45a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os \n",
    "import pandas as pd\n",
    "import sys\n",
    "    \n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "print(NOTEBOOK_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0cf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/datasets/gretelai/synthetic_text_to_sql\n",
    "dataset = load_dataset(\"gretelai/synthetic_text_to_sql\")\n",
    "\n",
    "print(\"Available data subsets:\", dataset.keys())\n",
    "print(\"Features: \")\n",
    "for k, v in dataset[\"train\"][0].items():\n",
    "    print(f\"---> {k:30}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def create_sharegpt_format(df: pd.DataFrame) -> List[dict]:\n",
    "    result = []\n",
    "    for _, row in df.iterrows():\n",
    "        result.append({\n",
    "            \"conversations\": [\n",
    "                {\"from\": \"user\", \"value\": row[\"text\"]},\n",
    "                {\"from\": \"assistant\", \"value\": row[\"sql\"]}\n",
    "            ]\n",
    "        })\n",
    "    return result\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "for split_name in [\"train\", \"test\"]:\n",
    "    df = pd.DataFrame(dataset[split_name])\n",
    "    sharegpt_data = create_sharegpt_format(df)\n",
    "\n",
    "    output_file = Path(f\"data/dataset_{split_name}.json\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(sharegpt_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\" Saved: {output_file} â€” {len(sharegpt_data)} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc65e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!mkdir -p $NOTEBOOK_DIR/LLaMA-Factory/data/\n",
    "!cp -r $NOTEBOOK_DIR/data/* $NOTEBOOK_DIR/LLaMA-Factory/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b37cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    \"model_name_or_path\": \"TinyLlama/TinyLlama-1.1B-Chat\",\n",
    "    \"template\": \"chatml\",\n",
    "    \"finetuning_type\": \"lora\",\n",
    "    \"dataset\": \"dataset_train\",\n",
    "    \"dataset_dir\": \"./data\",\n",
    "    \"val_set_size\": 0.01,\n",
    "    \"output_dir\": \"output/tinyllama-sql\",\n",
    "    \"cutoff_len\": 1024,\n",
    "    \"fp16\": True,\n",
    "    \"lora_rank\": 8,\n",
    "    \"lora_alpha\": 16,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"gradient_accumulation_steps\": 2,\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"save_steps\": 250,\n",
    "    \"logging_steps\": 10,\n",
    "    \"report_to\": \"none\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"plot_loss\": True,\n",
    "    \"warmup_steps\": 50,\n",
    "    \"flash_attn\": False,\n",
    "    \"lora_target\": \"q_proj,v_proj\",\n",
    "    \"use_dora\": True,\n",
    "    \"stage\": \"sft\"\n",
    "}\n",
    "\n",
    "config_path = f\"{NOTEBOOK_DIR}/LLaMA-Factory/train_tinyllama.json\"\n",
    "with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(training_args, f, indent=2)\n",
    "print(f\"Config saved to: {config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2d4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git || echo \"Already cloned\"\n",
    "%cd $NOTEBOOK_DIR/LLaMA-Factory\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd $NOTEBOOK_DIR/LLaMA-Factory\n",
    "# !CUDA_VISIBLE_DEVICES=0 python src/train_bash.py --config_file train_tinyllama.json"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
